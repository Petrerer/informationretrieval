{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "405b03d0",
      "metadata": {
        "id": "405b03d0"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a59cd04",
      "metadata": {
        "id": "6a59cd04"
      },
      "source": [
        "When working with a text you have to take into account families of words e.g. dog, dogs, doggy. The most popular techniques helping to deal with this issue are lemmatization and stemming. Both are special cases of normalization. They identify a canonical representative for a set of related word forms.\n",
        "\n",
        "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
        "However, the two words differ in their flavor. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534ab0ac",
      "metadata": {
        "id": "534ab0ac"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "wordnet = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e454272c",
      "metadata": {
        "id": "e454272c"
      },
      "outputs": [],
      "source": [
        "print(\"{:15}{:15}{:15}{:15}\".format(\"Word\",\"Porter\",\"Lancaster\",\"WordNet\"))\n",
        "for word in [\"was\", \"cats\", \"played\", \"mechanical\", \"friend\", \"friendship\"]:\n",
        "    print(\"{:15}{:15}{:15}{}\".format(word, porter.stem(word), lancaster.stem(word), wordnet.lemmatize(word, pos=\"v\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb35f6cb",
      "metadata": {
        "id": "eb35f6cb"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Poznań University of Technology, PUT (Polish name: Politechnika Poznańska) is a university in Poznań,\n",
        "Poland. Poznań University of Technology is known as one of the best technical universities in Poland. URAP\n",
        "ranked PUT as in top 6% of world universities and Webometrics ranked it at no. 842 in the world by Google\n",
        "citations for the year 2015. In 1995 it became the first Polish university to become a member of the Conference\n",
        "of European Schools for Advanced Engineering Education and Research (CESAER), an organization comprising the best\n",
        "technical universities in Europe. The university is also a member of the Socrates-Erasmus programme for exchange\n",
        "students from all over Europe, promoting advanced engineering and a European dimension. The university is home to\n",
        "many organizations and student circles, and the radio station Afera 98.6 MHz. The university has over\n",
        "21,000 students and over 1100 academic staffs.\"\"\".replace('\\n',' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1acf29",
      "metadata": {
        "id": "ff1acf29"
      },
      "outputs": [],
      "source": [
        "porter.stem(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e77ef660",
      "metadata": {
        "id": "e77ef660"
      },
      "source": [
        "As a first step, we have to transform a string into a list of words. It's not as trivial as you might think. Thankfully there are libraries with such functions already implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ca975e",
      "metadata": {
        "id": "54ca975e"
      },
      "outputs": [],
      "source": [
        "word_tokenize(text), len(word_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe63e856",
      "metadata": {
        "id": "fe63e856"
      },
      "outputs": [],
      "source": [
        "wordpunct_tokenize(text), len(wordpunct_tokenize(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26914657",
      "metadata": {
        "id": "26914657"
      },
      "outputs": [],
      "source": [
        "for x in word_tokenize(text):\n",
        "    print(\"{:20} - {:20}\".format(x, porter.stem(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d5f3773",
      "metadata": {
        "id": "8d5f3773"
      },
      "outputs": [],
      "source": [
        "print(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1942f22",
      "metadata": {
        "id": "d1942f22"
      },
      "source": [
        "## Task\n",
        "Write function which takes string as input and returns list of stems for reasonable words. Filter out stop words and non-words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "836dfa9f",
      "metadata": {
        "id": "836dfa9f"
      },
      "outputs": [],
      "source": [
        "def custom_stemmer(string):\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2459a26",
      "metadata": {
        "id": "d2459a26"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2d778f98",
      "metadata": {
        "id": "2d778f98"
      },
      "source": [
        "## Task\n",
        "Convert a date of yyyy-mm-dd format to dd.mm.yyyy format using regular expresions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c32ada9f",
      "metadata": {
        "id": "c32ada9f"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "s = [\"1985-12-4\",\n",
        "    \"asd 12-132-133\",\n",
        "    \"Afs!@#-2055-12-12\",\n",
        "    \"02-03-2020\",\n",
        "    \"Is it a date 2012-11-01?\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ed7ccc",
      "metadata": {
        "id": "c6ed7ccc"
      },
      "source": [
        "The following output is expected:\n",
        "\n",
        "4.12.1985<br>\n",
        "asd 12-132-133<br>\n",
        "Afs!@#-12.12.2055<br>\n",
        "02-03-2020<br>\n",
        "Is it a date 01.11.2012?<br>\n",
        "\n",
        "Use re.sub function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ccd1022",
      "metadata": {
        "id": "9ccd1022"
      },
      "outputs": [],
      "source": [
        "for x in s:\n",
        "    print(re.sub(r'(\\d+)-(\\d+).*', r'first number: \\g<1>; second number: \\g<2>', x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bddf3273",
      "metadata": {
        "id": "bddf3273"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e5b10495",
      "metadata": {
        "id": "e5b10495"
      },
      "source": [
        "# OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "901f1ba8",
      "metadata": {
        "id": "901f1ba8"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36af8d7d",
      "metadata": {
        "id": "36af8d7d"
      },
      "outputs": [],
      "source": [
        "url = \"https://i.ibb.co/8d564bB/example-01.png\"\n",
        "\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e58af91",
      "metadata": {
        "id": "3e58af91"
      },
      "outputs": [],
      "source": [
        "print(pytesseract.image_to_string(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edf03dd",
      "metadata": {
        "id": "9edf03dd"
      },
      "outputs": [],
      "source": [
        "url = \"https://i.ibb.co/n63mZfb/example-02.png\"\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecdbf58",
      "metadata": {
        "id": "4ecdbf58"
      },
      "outputs": [],
      "source": [
        "print(pytesseract.image_to_string(img))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66de485c",
      "metadata": {
        "id": "66de485c"
      },
      "source": [
        "## Task\n",
        "Read perfectly text from example_02"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84ae1b01",
      "metadata": {
        "id": "84ae1b01"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee919312",
      "metadata": {
        "id": "ee919312"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\"https://i.ibb.co/1ffsFkx/vin.png\")\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a2417c6",
      "metadata": {
        "id": "5a2417c6"
      },
      "outputs": [],
      "source": [
        "print(pytesseract.image_to_string(img))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064ceaf5",
      "metadata": {
        "id": "064ceaf5"
      },
      "source": [
        "## Task 5\n",
        "Read nearly perfectly text from vin.png, 1 error allowed (missing char, additional char, wrong char), 0/O is not an error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb0f7083",
      "metadata": {
        "id": "fb0f7083"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8194542",
      "metadata": {
        "id": "f8194542"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}