{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKreaeQ7vTQ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
        "!tar -xf images.tar\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "source_dir = \"Images\"\n",
        "test_dir = \"test_Images\"\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)\n",
        "\n",
        "for subdir in os.listdir(source_dir):\n",
        "    subdir_path = os.path.join(source_dir, subdir)\n",
        "\n",
        "    if os.path.isdir(subdir_path):\n",
        "        test_subdir_path = os.path.join(test_dir, subdir)\n",
        "        if not os.path.exists(test_subdir_path):\n",
        "            os.makedirs(test_subdir_path)\n",
        "        images = [f for f in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, f))]\n",
        "\n",
        "        num_images_to_move = min(10, len(images)) # Ensure we don't try to move more images than exist\n",
        "        selected_images = random.sample(images, num_images_to_move)\n",
        "        for image_file in selected_images:\n",
        "            source_image_path = os.path.join(subdir_path, image_file)\n",
        "            test_image_path = os.path.join(test_subdir_path, image_file)\n",
        "            shutil.move(source_image_path, test_image_path)"
      ],
      "metadata": {
        "id": "2MwJeyVx3zQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the easiest ways to prepare image data for training is by using data generators. They eliminate the need to manually load data into memory, helping prevent memory overflow issues. Additionally, data augmentation and preprocessing can be conveniently performed during this stage."
      ],
      "metadata": {
        "id": "SvXx6970EquR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.3,\n",
        "    shear_range=0.01,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    source_dir,\n",
        "    target_size=(192, 192),\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    source_dir,\n",
        "    target_size=(192, 192),\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "testgen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "test_generator = testgen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(192, 192),\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=32,\n",
        ")"
      ],
      "metadata": {
        "id": "n-ciJSZU5h6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "Try to predict breed of a dog from an image using cnn. You can directly use train_generator, val_generator in a fit function"
      ],
      "metadata": {
        "id": "umAD8nar6rED"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRdMkSDRA883"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1QIJY9GSA9DX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXZEY-mSA9Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you probably noticed it's not so easy. We can enhance the process by using a CNN pretrained on a set of general images. Of course, it cannot be used directly, but the whole feature extraction part can be copied and then maybe slightly adjusted."
      ],
      "metadata": {
        "id": "Q4uS_E_h6zhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(192, 192, 3))\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "ggubPd3J7J9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "The model is quite big, but it's already trained so we froze the weights to not change them during the training phase. After the training is finished the weights can be unfrozen and the training can be repeated to adjust them even better. Now we have only the convolutional part, add the missing part to perform a classification, and compare the results with a model built from scratch."
      ],
      "metadata": {
        "id": "CG-90LjP8dj8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tb58mcho-V5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qRxcE8K9-Vsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image segmentation is an image-to-image task where the output is a binary image with the same shape as the input showing the location of a given object e.g. roads, humans, or signs.\n",
        "\n",
        "A U-net architecture is a popular model used in this task. It allows us to capture not only local patterns and map them to the output. It's presented in a picture below. Of course, it's just an example and the number of layers or number of neurons do not have to be copied one to one."
      ],
      "metadata": {
        "id": "rUf22djG-WWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20220614121231/Group14.jpg\">\n",
        "\n",
        "https://www.geeksforgeeks.org/u-net-architecture-explained/"
      ],
      "metadata": {
        "id": "qdP4PmnA-cDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "Download a retina blood vessel dataset https://www.kaggle.com/datasets/abdallahwagih/retina-blood-vessel create and train an U-net. You can use transfer learning, but it's not a must"
      ],
      "metadata": {
        "id": "P3VLLhAKA-Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tzXGlh_JGNOe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}