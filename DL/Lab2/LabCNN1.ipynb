{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhpg5E83zHSq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage import convolve\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.datasets import mnist, cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7_eDJLK4g_D"
      },
      "source": [
        "Convolution is an opeartion on two matrices $a = [a_1, a_0], b = [b_0, b_1, b_2, b_3, b_4]$ (a vector is reversed in a classical convolution)\n",
        "\n",
        "$conv(b,a) = [a_0*b_0 + a_1 * b_1, a_0 * b_1 + a_1 * b_2, a_0 * b_2 + a_1 * b_3, a_0 * b_3 + a_1 * b_4]$\n",
        "\n",
        "so we slide one matrix over the other and calculate a dot product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwMHsfE7zT89"
      },
      "outputs": [],
      "source": [
        "x1 = np.array([1, 2, 3, 4, 5])\n",
        "x2 = np.array([1, 2])\n",
        "np.convolve(x1, x2, mode='valid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kU3FmcLdQ74"
      },
      "source": [
        "The resulting matrix will be smaller than the input due to the nature of the operation. We can force the output to be the same size as the input or apply a dot operation on each partially overlapping part. Then the result will be $[a_1 * b_0 + a_0*b_0 + a_1 * b_1, ..., a_0 * b_4]$ so it's an equivalent of using zero padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjrfhME9dO0c"
      },
      "outputs": [],
      "source": [
        "np.convolve(x1, x2, mode='same')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMTVMUaBdFFi"
      },
      "outputs": [],
      "source": [
        "np.convolve(x1, x2, mode='full')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SQsCnMfAYFl"
      },
      "source": [
        "Convolution can be used for 2 or more dimensional data. An example of how it is applied to a 2d matrix is presented below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBon4FpLAHcZ"
      },
      "source": [
        "<img src=\"https://d29g4g2dyqv443.cloudfront.net/sites/default/files/pictures/2018/convolution-2.gif\" width=\"750\" align=\"center\">\n",
        "\n",
        "https://developer.nvidia.com/discover/convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HLgnAAK-50"
      },
      "source": [
        "Convolutions are widely used in image processing e.g. sobel filter can be used to detect edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UrtHoNLADOo"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\"https://kapitan-bomba-wiki.netlify.app/kurvinox-removebg-preview.png\")\n",
        "img = Image.open(BytesIO(response.content)).convert(\"L\")  # Convert to grayscale\n",
        "img_array = np.array(img)\n",
        "\n",
        "sobel_x = np.array([[-1, 0, 1],\n",
        "                   [-2, 0, 2],\n",
        "                   [-1, 0, 1]])\n",
        "\n",
        "sobel_y = np.array([[-1, -2, -1],\n",
        "                   [0, 0, 0],\n",
        "                   [1, 2, 1]])\n",
        "\n",
        "edges_x = convolve(img_array, sobel_x)\n",
        "edges_y = convolve(img_array, sobel_y)\n",
        "edges = np.abs(edges_x + edges_y)\n",
        "\n",
        "\n",
        "plt.imshow(img_array, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(edges, cmap='gray')\n",
        "plt.title('Sobel Filtered Image')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoOuWYD1uGUd"
      },
      "source": [
        "Typically images are represented as a 3d matrix with e.g. RGB channels. The default approach would be to use 3d convolutions, however, since there is no spatial data to be extracted between channels we still use 2d convolutions with depth equal to the number of channels. So when applying a convolution on an image with a 3x3 kernel it is a 3x3x3 kernel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HliumXH_hAnZ"
      },
      "source": [
        "Although powerful the filters are not easy to use. Which one to choose, and how to combine them it's not easy to do it manually so we want it to be done automatically and that's what convolutional neural networks are for. The weights model learns during the training are exactly the values of the convolutional filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhfkFstRfzUP"
      },
      "outputs": [],
      "source": [
        "x_size = 32\n",
        "y_size = 32\n",
        "dummy_dataset = np.random.randn(1, x_size, y_size, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1, (3, 3), activation='relu', input_shape=(x_size, y_size, 3)))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aho4Hd7kmwcg"
      },
      "source": [
        "Our dataset consists of an image 32x32 with three channels. The model has one layer with one 'neuron'/filter of size 3x3(x3 - depth). It means 3 * 3 * 3=27 trainable parameters of the filter +1 parameter for bias. The output is of shape 30x30 since only 'valid' dot operations are performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aTe9Phmmvsp"
      },
      "outputs": [],
      "source": [
        "x_size = 3200\n",
        "y_size = 3200\n",
        "dummy_dataset = np.random.randn(1, x_size, y_size, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(1, (3, 3), activation='relu', input_shape=(x_size, y_size, 3)))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LlgsQ2_xuE4"
      },
      "source": [
        "Due to the nature of the convolution, increasing the size of an input image does not result in a higher number of trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIMA-rYPfzYD"
      },
      "outputs": [],
      "source": [
        "x_size = 3200\n",
        "y_size = 3200\n",
        "dummy_dataset = np.random.randn(1, x_size, y_size, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(x_size, y_size, 3)))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noFHqC1jyoJ_"
      },
      "source": [
        "If more 'neurons' are used each creates a new channel in the output, thus the number of channels is equal to the number of neurons.\n",
        "\n",
        "Since the output is also in an image form (2d matrix with channels), the convolutional layers can be easily stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioQpN8Z1fzbM"
      },
      "outputs": [],
      "source": [
        "x_size = 3200\n",
        "y_size = 3200\n",
        "dummy_dataset = np.random.randn(1, x_size, y_size, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(x_size, y_size, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqf79kii0SIp"
      },
      "source": [
        "Due to the nature of the operation, we don't even have to specify the size of an input image if only convolutional layers are used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw_TLmhq0S6v"
      },
      "outputs": [],
      "source": [
        "x_size = 3200\n",
        "y_size = 3200\n",
        "dummy_dataset = np.random.randn(1, x_size, y_size, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(None, None, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeawWJm_fzdx"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIjzkXb40umX"
      },
      "source": [
        "Mnist is a popular dataset of handwritten digits. The aim is to predict which digit is in the picture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIMgeBQLfzgV"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    plt.imshow(x_train[i].reshape(28, 28), cmap='gray')\n",
        "    plt.title(y_train[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVbQw5go01Ii"
      },
      "outputs": [],
      "source": [
        "x_size = 28\n",
        "y_size = 28\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(x_size, y_size, 1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8HENeca1mFn"
      },
      "source": [
        "We want to use conv layers to extract features and then at some point switch with these features to a classical MLP. The aim of a Flatten function is to transform the 3d output (2d image with channels) to a flat vector that can be an input to a MLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEXwOhY51FjO"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs=1, batch_size=256, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWsCM0iI2k-Q"
      },
      "source": [
        "As you can see the size of an image decreases slowly with each layer, therefore after applying the Flatten layer the size of the obtained vector is quite big. To make the process faster an operation called Pooling can be used. It can be seen as an image size reduction. Different types of Pooling can be used e.g. Max or Average, Max is the most popular due to its efficiency. The procedure is simple, assuming we have an input image 4x4 and use MaxPooling with kernel 2x2 the input is divided into 4 squares of the same size as the kernel, and from each the max value is extracted.\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/333593451/figure/fig2/AS:765890261966848@1559613876098/llustration-of-Max-Pooling-and-Average-Pooling-Figure-2-above-shows-an-example-of-max_W640.jpg\" width=\"750\" align=\"center\">\n",
        "\n",
        "https://paperswithcode.com/method/max-pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h99GJnbY2lJs"
      },
      "outputs": [],
      "source": [
        "x_size = 28\n",
        "y_size = 28\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(x_size, y_size, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrJ8q-G73tBf"
      },
      "source": [
        "Now the model is much smaller and will learn faster. The difference is much higher when dealing with big images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWfRAoz62oyC"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs=2, batch_size=256, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTSyjenuFXTm"
      },
      "source": [
        "## Task 1\n",
        "Try to get the best score with different architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLkrPkPvFWpV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_qJKCq0_kXc"
      },
      "source": [
        "## Task2\n",
        "Create a model to distinguish cats and dogs.\n",
        "\n",
        "Typically we normalize data before using a neural network. It makes the learning process easier and faster. We can include this procedure inside a network. After each layer the values are transformed and no longer standardized. We can again normalize them using BatchNormalization after each transformation (convolution). You can check how adding this layer affects the learning process.\n",
        "\n",
        "Dropout is a popular technique to prevent overfitting. It randomly turns off (drops out) a given fraction of outputs from the previous layer. You can try to apply it if the model performs significantly better on the training set compared to the validation one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SH46xUw5o1T"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train = y_train[..., 0]\n",
        "y_test = y_test[..., 0]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "classes = [3, 5]\n",
        "x_train = x_train[np.isin(y_train, classes)]\n",
        "y_train = y_train[np.isin(y_train, classes)]\n",
        "x_test = x_test[np.isin(y_test, classes)]\n",
        "y_test = y_test[np.isin(y_test, classes)]\n",
        "\n",
        "y_train = np.where(y_train == 3, 0, 1)\n",
        "y_test = np.where(y_test == 3, 0, 1)\n",
        "\n",
        "for x in np.random.randint(0, len(x_train), 10):\n",
        "    plt.imshow(x_train[x])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z-l-6BwEcHv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2KyeCSIqg3a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeQG2JX7qg3a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QW9uyayqg3a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRaCrR-yEqea"
      },
      "source": [
        "In machine learning and especially in deep learning the rule of thumb says the more data the better, of course, the quality of the data is also very important. With images, it's very easy to extend the dataset by performing simple operations like rotation, shift, gamma correction, etc. This process is called data augmentation. There are ready-to-use tools supporting the process, however, it's not recommended to use them without any analysis. For example, in the mnist dataset it makes no sense to flip the image since the result of this operation is not something we expect in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8sEVVpS5o6y"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\"https://kapitan-bomba-wiki.netlify.app/kurvinox-removebg-preview.png\")\n",
        "img = Image.open(BytesIO(response.content))\n",
        "x = np.array(img)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "x = x.reshape((1,) + x.shape)\n",
        "batch = datagen.flow(x)\n",
        "for i, x in enumerate(batch):\n",
        "  plt.imshow(x[0].astype(int))\n",
        "  plt.title(f'Augmented Image {i}')\n",
        "  plt.show()\n",
        "  if i > 6:\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ2Xn8VguPZj"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "Use data augmentation and data generator to train the best model you can. If you want you can use a dataset with better images e.g. https://www.microsoft.com/en-us/download/details.aspx?id=54765"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl5TeZwwqg3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}